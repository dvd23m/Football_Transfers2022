{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8075a342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from datetime import datetime, date, timedelta\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df234f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User agent\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.60 Safari/537.17'}\n",
    "\n",
    "# Create defaultdict\n",
    "players = defaultdict(list)\n",
    "teams_links = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7977466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_pages(text_to_split):\n",
    "    '''\n",
    "    This function extract number from text obtained from title property from \"last page button\"\n",
    "       \n",
    "    Params: \n",
    "        text_to_split(string): Contains text like \"Go the last page (page 19)\"\n",
    "    Return:\n",
    "        int : The extracted number. For instance 19\n",
    "    '''\n",
    "    return int(re.findall('[0-9]+', text_to_split)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_web(url, current_date):\n",
    "    '''\n",
    "        This function performs data extraction and create a defaultdict.\n",
    "        \n",
    "        Use a For loop to go through each webs and extract the name, position, age,\n",
    "        current club, new club and both leagues, cost of operation and date of these operation\n",
    "        about all players\n",
    "        \n",
    "        Params:\n",
    "            url(string): request url\n",
    "            current_date: datetime current date\n",
    "    '''    \n",
    "    r = requests.get(url, headers=headers)\n",
    "    soup = BS(r.text, 'lxml')\n",
    "    # Call to the function to get the number of pages of current_date date\n",
    "    pages = number_of_pages(\n",
    "        soup.select_one('li.tm-pagination__list-item.tm-pagination__list-item--icon-last-page > a')['title'])\n",
    "    \n",
    "    for x in range(1, pages):\n",
    "        r = requests.get(f\"https://www.transfermarkt.com/transfers/transfertagedetail/statistik/top/land_id_zu/0/land_id_ab/0/leihe//datum/{current_date}/sort//plus/1/page/{x}\", headers=headers)\n",
    "        soup = BS(r.text, 'lxml')\n",
    "        # Get the table items\n",
    "        table = soup.select('table.items>tbody>tr')\n",
    "        for tr in table:\n",
    "            \n",
    "            players['name'].append(tr.find_all('td', recursive=False)[0].select('td')[1].text.strip())\n",
    "            players['position'].append(tr.find_all('td', recursive=False)[0].select('td')[2].text.strip())\n",
    "            players['age'].append(tr.find_all('td', recursive=False)[1].text)\n",
    "            players['origin_club'].append(tr.find_all('td', recursive=False)[3].select('td')[0].select('img')[0]['title'].strip())\n",
    "            players['league_origin_club'].append(tr.find_all('td', recursive=False)[3].select('td')[2].text.strip())\n",
    "            players['new_club'].append(tr.find_all('td', recursive=False)[4].select('td')[0].select('img')[0]['title'].strip())\n",
    "            players['league_new_club'].append(tr.find_all('td', recursive=False)[4].select('td')[2].text.strip())\n",
    "            players['cost'].append(tr.find_all('td', recursive=False)[5].text.strip())\n",
    "            players['date_of_transfer'].append(current_date.strftime('%Y-%m-%d'))\n",
    "        print(players)\n",
    "    # Save data in json                  \n",
    "    with open('Summer22_FootballTransfers.json', 'w', encoding='utf-8') as file_json:\n",
    "        json.dump(players, file_json, indent=4, ensure_ascii=False)\n",
    "    return players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0540f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_date(first_market_day, current_date):\n",
    "    '''\n",
    "        This function creates the first page to scraping for each day, since current_date to\n",
    "        first_market_day.\n",
    "        \n",
    "        Params:\n",
    "            first_market_day(datetime)\n",
    "    '''\n",
    "    while current_date != first_market_day:\n",
    "        # Make url\n",
    "        url_base = f\"https://www.transfermarkt.es/transfers/transfertagedetail/statistik/top/land_id_zu/0/land_id_ab/0/leihe//datum/{current_date.strftime('%Y-%m-%d')}/page/1\"\n",
    "        # Call function to get data\n",
    "        players_dict = parse_web(url_base, current_date)\n",
    "        current_date = current_date - timedelta(days=1)\n",
    "    return players_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e543fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE THIS FUNCTION IF YOU WANT TO DO A SCRAPING FROM A SPECIFIC DATE TO TODAY\n",
    "'''def calculate_days_to_scrap(fromDay):\n",
    "    today = date.today()-timedelta(days=1)\n",
    "    today = datetime(today.year, today.month, today.day)\n",
    "    total_days = (today - fromDay).days\n",
    "    if total_days !=0:\n",
    "        first_day = today - timedelta(days=(total_days))\n",
    "        players_dict = check_date(first_day, today)\n",
    "    return players_dict\n",
    "'''\n",
    "\n",
    "#  USE THIS FUNCTION IF YOU WANT TO DO A SCRAPING ONLY OF SUMMER MARKET WINDOW\n",
    "def calculate_days_to_scrap(fromDay):\n",
    "    last_day = datetime.strptime('2022-07-02', '%Y-%m-%d')\n",
    "    players_dict = check_date(fromDay, last_day)   \n",
    "    return players_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a29e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start date for scraping\n",
    "players_dict = calculate_days_to_scrap(datetime.strptime('2022-06-30', '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed498838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv\n",
    "df_players = pd.DataFrame(players_dict)\n",
    "df_players.to_csv('Summer22_FootballTransfers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
